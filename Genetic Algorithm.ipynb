{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import string\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenized_files={}\n",
    "total_no_of_files=0\n",
    "os.chdir(\"C://Users//Hp//Desktop//Projects//Text Mining//bbcsport\")\n",
    "directories = os.listdir()\n",
    "for directory in directories:\n",
    "    path = os.path.join(os.getcwd(),directory)\n",
    "    os.chdir(path)\n",
    "    files = os.listdir()\n",
    "    temp = []\n",
    "    for file in files:\n",
    "        with open(file,'r') as curr_file:\n",
    "            s = curr_file.read()\n",
    "            s = re.sub(r'\\d+','',s)\n",
    "            s = s.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "            s = s.strip()\n",
    "            s = s.lower()\n",
    "            t1 = nltk.tokenize.word_tokenize(s)\n",
    "            t2 = []\n",
    "            for word in t1:\n",
    "                lem_word= lemmatizer.lemmatize(word)\n",
    "                if(lem_word not in stop_words):\n",
    "                    t2.append(lem_word)\n",
    "            temp.append(t2)\n",
    "            total_no_of_files+=1\n",
    "    tokenized_files[directory]=temp\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a unique set of all words\n",
    "wordset=[]\n",
    "for key in tokenized_files.keys():\n",
    "    for file in tokenized_files[key]:\n",
    "        for word in file:\n",
    "            wordset.append(word)\n",
    "        \n",
    "wordset = list(set(wordset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the frequency of occurence of a specific word among all documents\n",
    "wordFreq={}\n",
    "for word in wordset:\n",
    "    count=0\n",
    "    for key in tokenized_files.keys():\n",
    "        for file in tokenized_files[key]:\n",
    "            if word in file:\n",
    "                count+=1\n",
    "    wordFreq[word]=count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the tf-idf values for all words in the wordset for all documents\n",
    "X = []\n",
    "for key in tokenized_files.keys():\n",
    "    file_number=0\n",
    "    for file in tokenized_files[key]:\n",
    "        file_tfidf = []\n",
    "        n = len(file)\n",
    "        for word in wordset:\n",
    "            a = file.count(word)\n",
    "            tf = a/float(n)\n",
    "            idf= math.log(total_no_of_files/float(wordFreq[word]))\n",
    "            file_tfidf.append(tf*idf)\n",
    "        X.append(file_tfidf)\n",
    "X_copy = copy.deepcopy(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(737, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = copy.deepcopy(X_copy)\n",
    "X = np.array(X)\n",
    "u,s,vh = np.linalg.svd(X)\n",
    "X = u[:,0:5]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=5\n",
    "P=25\n",
    "cross_over_rate=0.05\n",
    "mutation_rate=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def population_initialization():\n",
    "    '''\n",
    "    Parameters:\n",
    "        K : Number of clusters\n",
    "        P : Size of Initial Population of chromosomes\n",
    "    Output:\n",
    "        P chromosomes of length K*N where N is the number of features\n",
    "    Function:\n",
    "        Takes K random datapoints from the dataset and appends them to create a chromosome\n",
    "        This is repeated P times\n",
    "    '''\n",
    "    population=[]\n",
    "    for i in range(P):\n",
    "        chromosome=[]\n",
    "        for j in range(K):\n",
    "            chromosome.append(X[random.randint(0,len(X)-1)])\n",
    "        chromosome=list(itertools.chain(*chromosome))\n",
    "        population.append(chromosome)\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to decide cluster using Euclidean distance\n",
    "def cosine_similarity(centers,datapoint):\n",
    "    '''\n",
    "    Parameters:\n",
    "        centers: List of Cluster centers\n",
    "        K : number of clusters\n",
    "        datapoint : Datapoint\n",
    "    Output:\n",
    "        Cluster number alloted based on maximum cosine_similarity of the datapoint with the cluster centers\n",
    "    '''\n",
    "    #Cosine Similarity    \n",
    "    t = np.asarray(datapoint)\n",
    "    normt= np.linalg.norm(t)\n",
    "    dot=[]\n",
    "    for i in range(K):\n",
    "        temp_center = np.asarray(centers[i])\n",
    "        normc = np.linalg.norm(temp_center)\n",
    "        cos_sim_value=np.dot(t,temp_center)/(normt*normc)\n",
    "        dot.append(cos_sim_value)\n",
    "    \n",
    "    return dot.index(max(dot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist_based_center_decision(centers,datapoint):\n",
    "    t = np.asarray(datapoint)\n",
    "    dist=[]\n",
    "    for i in range(K):\n",
    "        temp_center = np.asarray(centers[i])\n",
    "        dist.append(np.linalg.norm(temp_center-t))\n",
    "    return dist.index(min(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(chromosome):\n",
    "    '''\n",
    "    Parameters:\n",
    "        K: Number of clusters\n",
    "        chromosome: Contains the centers of K clusters\n",
    "        X : dataset\n",
    "    Output:\n",
    "        A fitness value f for the input chromosome\n",
    "    Function:\n",
    "        1. Initializes K centers using the chromosome\n",
    "        2. Divides the dataset into K clusters using functions like cosine_similarity or euclidean_distance\n",
    "        3. Recomputer cluster centers by averaging the datapoints of that cluster\n",
    "        4. Computer fitness value as follows:\n",
    "                M = sum from i in range(1,K)(Mi)\n",
    "                Mi= sum of distances of datapoints of a cluster from its center\n",
    "                fitness_value(f) = 1/M\n",
    "    '''\n",
    "    centers=[]\n",
    "    \n",
    "    #Dividing the chromosomes into centers\n",
    "    for i in range(K):\n",
    "        centers.append(chromosome[i*len(X[0]):len(X[0])*(i+1)])\n",
    "    \n",
    "    #Dividing the dataset into clusters\n",
    "    clusters={}\n",
    "    for i in range(K):\n",
    "        clusters[i]=[]\n",
    "    for i in range(len(X)):\n",
    "        clusters[euclidean_dist_based_center_decision(centers,X[i])].append(X[i])\n",
    "#         clusters[cosine_similarity(centers,X[i])].append(X[i])\n",
    "    \n",
    "    #Recomputing cluster centers\n",
    "    centers=[]\n",
    "    for i in range(K):\n",
    "        temp=clusters[i]\n",
    "        if len(temp)!=0:\n",
    "            centers.append((np.sum(np.asarray(temp),axis=0)/len(temp)).tolist())\n",
    "        else:\n",
    "            temp_list=np.zeros(len(X[0])).tolist()\n",
    "            centers.append(temp_list)\n",
    "    \n",
    "    #Computing fitness value\n",
    "#     M=0\n",
    "#     for i in range(K):\n",
    "#         temp=clusters[i]\n",
    "#         center=centers[i]\n",
    "#         for j in temp:\n",
    "#             M+=np.linalg.norm(np.asarray(j)-np.asarray(center))\n",
    "    \n",
    "    chromosome =[]\n",
    "    for i in range(len(centers)):\n",
    "        chromosome.extend(centers[i])\n",
    "    fitness_score = 1/davies_bouldin_index(chromosome)\n",
    "    return fitness_score,chromosome        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_evaluation(population):\n",
    "    '''\n",
    "    Parameters:\n",
    "        K: Number of clusters\n",
    "        population: Contains all the chromosomes of the current generation\n",
    "        X : dataset\n",
    "    Output:\n",
    "        A list of fitness scores of each chromosome in the parent\n",
    "    '''\n",
    "    fitness=[]\n",
    "    pop = []\n",
    "    for i in population:\n",
    "        fitness_value,recomputed_chromosome = fitness_function(i)\n",
    "        fitness.append(fitness_value)\n",
    "        pop.append(recomputed_chromosome)\n",
    "    return pop,fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roulette_wheel(fitness_scores):\n",
    "    sum_fitness_scores = np.sum(np.asarray(fitness_scores))\n",
    "    temp_fitness = copy.deepcopy(fitness_scores)\n",
    "    temp_fitness.sort(reverse=True)\n",
    "    t=[]\n",
    "    for i in range(len(fitness_scores)):\n",
    "        percentage_coverage=int(temp_fitness[i]*360/sum_fitness_scores)\n",
    "        for j in range(percentage_coverage):\n",
    "            t.append(i)\n",
    "    \n",
    "    temp=[]\n",
    "    for i in range(2):\n",
    "        toss=random.randint(0,len(t)-1)\n",
    "        temp.append(t[toss])\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_over(parent1,parent2,parent1_f_val,parent2_f_val):\n",
    "    temp = {}\n",
    "    fitness_scores=[]\n",
    "    fitness_scores.append(parent1_f_val)\n",
    "    fitness_scores.append(parent2_f_val)\n",
    "    temp[parent1_f_val]=parent1\n",
    "    temp[parent2_f_val]=parent2\n",
    "    for i in range(1,len(parent1)-1):\n",
    "        prob_of_cross_over_point = np.random.random_sample()\n",
    "        if prob_of_cross_over_point<cross_over_rate:\n",
    "            left_parent_1 = parent1[:i]\n",
    "            right_parent_1= parent1[i:]\n",
    "            left_parent_2 = parent2[:i]\n",
    "            right_parent_2= parent2[i:]\n",
    "            child1 = left_parent_1\n",
    "            child2 = left_parent_2\n",
    "            child1.extend(right_parent_2)\n",
    "            child2.extend(right_parent_1)\n",
    "            _,fitness_values = fitness_evaluation([child1,child2])\n",
    "            temp[fitness_values[0]]=child1\n",
    "            temp[fitness_values[1]]=child2\n",
    "            fitness_scores.extend(fitness_values)\n",
    "    max1=max(fitness_scores)\n",
    "    fitness_scores.remove(max1)\n",
    "    max2=max(fitness_scores)\n",
    "    return temp[max1],temp[max2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_over_function(population,fitness_scores):\n",
    "    '''\n",
    "    Parameters:\n",
    "        population: Parent population chromosomes\n",
    "        fitness_scores: fitness of parent population\n",
    "    Output:\n",
    "        children generation population\n",
    "    Function:\n",
    "        We select the 2 best chromosomes and 2 worst chromosomes and perform a cross-over between the bests and worsts and add\n",
    "        them to the population generating children generation population with 4 different chromosomes.\n",
    "    '''\n",
    "    for i in range(K//2):\n",
    "        t=roulette_wheel(fitness_scores)\n",
    "        t.sort()\n",
    "        c1i,c2i=t[0:2]\n",
    "        chromosome1 = population[c1i]\n",
    "        chromosome2 = population[c2i]\n",
    "\n",
    "        c1,c2 = cross_over(chromosome1,chromosome2,fitness_scores[c1i],fitness_scores[c2i])\n",
    "\n",
    "        population.append(c1)\n",
    "        population.append(c2)\n",
    "\n",
    "        del(population[c1i])\n",
    "        del(fitness_scores[c1i])\n",
    "        c2i=max(0,c2i-1)\n",
    "        del(population[c2i])\n",
    "        del(fitness_scores[c2i])\n",
    "\n",
    "        t,fitness = fitness_evaluation([c1,c2])\n",
    "        fitness_scores.extend(fitness)\n",
    "    return population,fitness_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(children):\n",
    "    '''\n",
    "    Parameters:\n",
    "        children: Children we get from the genetic cross-over in the previous stage\n",
    "        mutation_rate: Rate at which we want to mutate the children (0-1)\n",
    "    Output:\n",
    "        children with a mutated gene\n",
    "    Functions:\n",
    "        We randomly select a number between 0 and 1 using probably a gaussian distribution as mutation is not a frequent\n",
    "        phenomenon. If that value is less than mutation_rate we mutate the children.\n",
    "        For mutation we again generate a value alpha between 0 to 1. We then randomly select a position from the chromosome\n",
    "        and changes its value as following\n",
    "            let the value at the randomly selected position be v\n",
    "            v = v (+/-) 2*alpha*v if(v!=0)\n",
    "            v = v (+/-) 2*alpha   if(v==0)\n",
    "        (+/-) is selected randomly giving each a 50-50 chance\n",
    "    '''\n",
    "    for i in range(len(children)):\n",
    "        temp = np.random.rand(1)[0]\n",
    "        if temp<mutation_rate:\n",
    "            chromosome = children[i]\n",
    "            position = random.randint(0,len(chromosome)-1)\n",
    "            alpha = np.random.rand(1)[0]\n",
    "            toss = random.randint(0,1)\n",
    "            if toss==0:\n",
    "                toss=-1\n",
    "            if chromosome[position]==0.0:\n",
    "                chromosome[position]=chromosome[position]+toss*2*alpha\n",
    "            else:\n",
    "                chromosome[position]=chromosome[position]+toss*2*alpha*chromosome[position]\n",
    "            children[i]=chromosome\n",
    "            \n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intracluster_distances(chromosome):\n",
    "    centers=[]\n",
    "    \n",
    "    #Dividing the chromosomes into centers\n",
    "    for i in range(K):\n",
    "        centers.append(chromosome[i*len(X[0]):len(X[0])*(i+1)])\n",
    "    \n",
    "    #Dividing the dataset into clusters\n",
    "    clusters={}\n",
    "    for i in range(K):\n",
    "        clusters[i]=[]\n",
    "    for i in range(len(X)):\n",
    "        clusters[euclidean_dist_based_center_decision(centers,X[i])].append(X[i])\n",
    "   \n",
    "    intracluster_d=[]\n",
    "#     print(\"Clusters :\",end=' ')\n",
    "    for i in range(K):\n",
    "        M=0\n",
    "        temp=clusters[i]\n",
    "#         print(str(len(temp)),end=' ')\n",
    "        center=centers[i]\n",
    "        for j in temp:\n",
    "            M+=np.linalg.norm(np.asarray(j)-np.asarray(center))\n",
    "        if len(temp)==0:\n",
    "            M=0\n",
    "        else:\n",
    "            M=M/len(temp)\n",
    "        intracluster_d.append(M)\n",
    "#     print()\n",
    "    return intracluster_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def davies_bouldin_index(chromosome):\n",
    "    intra_distance = intracluster_distances(chromosome)\n",
    "    \n",
    "    centers=[]\n",
    "    #Dividing the chromosomes into centers\n",
    "    for i in range(K):\n",
    "        centers.append(chromosome[i*len(X[0]):len(X[0])*(i+1)])\n",
    "    \n",
    "    D = []\n",
    "    for i in range(K):\n",
    "        R = []\n",
    "        for j in range(K):\n",
    "            if i!=j:\n",
    "                M = np.linalg.norm(np.asarray(centers[i])-np.asarray(centers[j]))\n",
    "                r = (intra_distance[i]+intra_distance[j])/M\n",
    "                R.append(r)\n",
    "        D.append(max(R))\n",
    "    return (1/K)*(np.sum(np.asarray(D)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_func():\n",
    "    '''\n",
    "    Steps:\n",
    "    Repeat 1-5 till 1 chromosome remains in the population\n",
    "    1.Initialize Population\n",
    "    2.Compute fitness scores\n",
    "    3.Selection\n",
    "    4.Cross-over\n",
    "    5.Mutation\n",
    "    '''\n",
    "    population = population_initialization()\n",
    "    gen=0\n",
    "    for i in range(1):\n",
    "        gen+=1\n",
    "        population,fitness=fitness_evaluation(population)\n",
    "        children,fitness = cross_over_function(population,fitness)\n",
    "        children = mutation(children)\n",
    "        population=children\n",
    "        centers=[]\n",
    "        purity = 100000\n",
    "        for j in population:\n",
    "            purity = min(purity,davies_bouldin_index(j))\n",
    "        print(\"Generation: \"+str(gen)+\" | Purity: \"+str(purity))\n",
    "    return population[fitness.index(max(fitness))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(chromosome):\n",
    "    centers=[]\n",
    "    \n",
    "    #Dividing the chromosomes into centers\n",
    "    for i in range(K):\n",
    "        centers.append(chromosome[i*len(X[0]):len(X[0])*(i+1)])\n",
    "    \n",
    "    #Dividing the dataset into clusters\n",
    "    clusters={}\n",
    "    for i in range(K):\n",
    "        clusters[i]=[]\n",
    "    for i in range(len(X)):\n",
    "        clusters[euclidean_dist_based_center_decision(centers,X[i])].append(X[i])\n",
    "    \n",
    "    colors=['r','m','y','k','c']\n",
    "    fig=plt.figure()\n",
    "    ax = Axes3D(fig)\n",
    "    for i in range(K):\n",
    "        temp=clusters[i]\n",
    "        for j in temp:\n",
    "            ax.scatter(j[0], j[1], j[2], c=colors[i], marker='o')\n",
    "            ax.view_init(30, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chromosome = main_func()\n",
    "plot(chromosome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
